{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hw32.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GrigoryBartosh/hse08_ip/blob/master/hw3_neural_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zSgN3JaUqtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xeq-J61DMoYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd 'drive/My Drive/ip_hw_3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybArQ57lhUTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install wandb >> /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qRxFFBmUmhr1",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import copy\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import wandb\n",
        "\n",
        "from tqdm.auto import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "PATH_DATA = 'tl-signs-hse-itmo-2020-winter.zip'\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7jId6n6smhr5",
        "colab": {}
      },
      "source": [
        "xs, ys = [], []\n",
        "with zipfile.ZipFile(PATH_DATA, 'r') as zip_file:\n",
        "    with zip_file.open('train.csv') as file:\n",
        "        train_data = pd.read_csv(file)\n",
        "\n",
        "    for _, x in tqdm(train_data.iterrows()):\n",
        "        name, lable = x['filename'], x['class_number']\n",
        "        with zip_file.open(os.path.join('train', 'train', name)) as img_file:\n",
        "            image = Image.open(img_file).convert('RGB')\n",
        "        xs += [image]\n",
        "        ys += [lable]\n",
        "\n",
        "num_classes = max(ys) + 1\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(xs, ys, test_size=0.15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T4IFi7qkxxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SiamDataset(data.Dataset):\n",
        "    def __init__(self, xs, ys, do_aug=False):\n",
        "        self.xs = xs\n",
        "        self.ys = ys\n",
        "        self.do_aug = do_aug\n",
        "\n",
        "    def aug(self, x):\n",
        "        PF, PT = 0.2, 0.6\n",
        "\n",
        "        x = x.copy()\n",
        "        w, h, _ = x.shape\n",
        "        dx = np.random.randint(int(w * (PT - PF))) + int(w * PF)\n",
        "        dy = np.random.randint(int(h * (PT - PF))) + int(h * PF)\n",
        "        x1 = np.random.randint(w - dx)\n",
        "        y1 = np.random.randint(h - dy)\n",
        "        x2, y2 = x1 + dx, y1 + dy\n",
        "        x[x1:x2, y1:y2] = 0\n",
        "\n",
        "        return x\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.xs[index]\n",
        "        y = self.ys[index]\n",
        "\n",
        "        x = np.array(x)\n",
        "        x = self.aug(x) if self.do_aug else x\n",
        "\n",
        "        y = torch.LongTensor([y])\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.xs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4VFGYLJFmhr8",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "def collate_xs(xs):\n",
        "    xs = [transform(x) for x in xs]\n",
        "    xs = torch.stack(xs, axis=0)\n",
        "\n",
        "    return xs\n",
        "\n",
        "def collate_fn(data):\n",
        "    xs, ys = zip(*data)\n",
        "    \n",
        "    xs = collate_xs(xs)\n",
        "    ys = torch.cat(ys)\n",
        "\n",
        "    return xs, ys\n",
        "\n",
        "train_dataset = SiamDataset(x_train, y_train, do_aug=True)\n",
        "val_dataset = SiamDataset(x_val, y_val, do_aug=False)\n",
        "\n",
        "train_data_loader = data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=8,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "val_data_loader = data.DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=8,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zAWlIByBmhsB",
        "colab": {}
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1, padding=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, 3, \n",
        "                     stride, padding, bias=False)\n",
        "    \n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, 1, \n",
        "                     stride, padding=0, bias=False)\n",
        "\n",
        "\n",
        "class SimpleBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes=None, stride=1):\n",
        "        super(SimpleBlock, self).__init__()\n",
        "\n",
        "        if out_planes is None:\n",
        "            out_planes = in_planes\n",
        "\n",
        "        self.activ = nn.ReLU()\n",
        "\n",
        "        self.conv1 = conv3x3(in_planes, out_planes, stride)\n",
        "        self.ln1 = nn.BatchNorm2d(out_planes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.ln1(out)\n",
        "        out = self.activ(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResBasicBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes=None, stride=1):\n",
        "        super(ResBasicBlock, self).__init__()\n",
        "\n",
        "        planes = in_planes\n",
        "\n",
        "        if out_planes is None:\n",
        "            out_planes = planes\n",
        "\n",
        "        self.residual_conv = None\n",
        "        if stride != 1 or in_planes != out_planes:\n",
        "            self.residual_conv = conv1x1(in_planes, out_planes, stride)\n",
        "            self.residual_ln = nn.BatchNorm2d(out_planes)\n",
        "\n",
        "        self.activ = nn.ReLU()\n",
        "\n",
        "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
        "        self.ln1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, out_planes)\n",
        "        self.ln2 = nn.BatchNorm2d(out_planes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.ln1(out)\n",
        "        out = self.activ(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.ln2(out)\n",
        "\n",
        "        if self.residual_conv is not None:\n",
        "            identity = self.residual_conv(identity)\n",
        "            identity = self.residual_ln(identity)\n",
        "\n",
        "        out += identity\n",
        "        out = self.activ(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class MyNet(nn.Module):\n",
        "    def __init__(self, num_classes, in_dim=32):\n",
        "        super(MyNet, self).__init__()\n",
        "\n",
        "        self.embed_dim = in_dim * 2 ** 4\n",
        "\n",
        "        self.model = [SimpleBlock(3, in_dim, 2)]\n",
        "        for _ in range(3):\n",
        "            self.model += [ResBasicBlock(in_dim, in_dim * 2, 2),\n",
        "                           ResBasicBlock(in_dim * 2, in_dim * 2)]\n",
        "            in_dim = in_dim * 2\n",
        "        self.model += [conv3x3(in_dim, self.embed_dim, padding=0)]\n",
        "        self.model = nn.Sequential(*self.model)\n",
        "\n",
        "        self.linear = nn.Linear(self.embed_dim, num_classes)\n",
        "                 \n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        x = x.squeeze(dim=2)\n",
        "        x = x.squeeze(dim=2)\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MyResNet(nn.Module):\n",
        "    def __init__(self, num_classes, model='resnet18', pretrained=False):\n",
        "        super(MyResNet, self).__init__()\n",
        "                 \n",
        "        if model == 'resnet18':\n",
        "            model_type = models.resnet18\n",
        "        elif model == 'resnet34':\n",
        "            model_type = models.resnet34\n",
        "        elif model == 'resnet50':\n",
        "            model_type = models.resnet50\n",
        "        elif model == 'resnet101':\n",
        "            model_type = models.resnet101\n",
        "        elif model == 'resnet152':\n",
        "            model_type = models.resnet152\n",
        "\n",
        "        self.model = model_type(pretrained=pretrained)\n",
        "        \n",
        "        if pretrained:\n",
        "            for parma in self.model.parameters():\n",
        "                parma.requires_grad = False\n",
        "\n",
        "        num_ftrs = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "                 \n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class MyVGG(nn.Module):\n",
        "    def __init__(self, num_classes, model='vgg11', pretrained=False):\n",
        "        super(MyVGG, self).__init__()\n",
        "                 \n",
        "        if model == 'vgg11':\n",
        "            model_type = models.vgg11_bn\n",
        "        elif model == 'vgg16':\n",
        "            model_type = models.vgg16_bn\n",
        "        elif model == 'vgg19':\n",
        "            model_type = models.vgg19_bn\n",
        "\n",
        "        self.model = model_type(pretrained=pretrained)\n",
        "        \n",
        "        if pretrained:\n",
        "            for parma in self.model.parameters():\n",
        "                parma.requires_grad = False\n",
        "\n",
        "        num_ftrs = self.model.classifier[6].in_features\n",
        "        self.model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "                 \n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class MyDense(nn.Module):\n",
        "    def __init__(self, num_classes, model='densenet121', pretrained=False):\n",
        "        super(MyDense, self).__init__()\n",
        "                 \n",
        "        if model == 'densenet121':\n",
        "            model_type = models.densenet121\n",
        "        elif model == 'densenet161':\n",
        "            model_type = models.densenet161\n",
        "        elif model == 'densenet169':\n",
        "            model_type = models.densenet169\n",
        "        elif model == 'densenet201':\n",
        "            model_type = models.densenet201\n",
        "\n",
        "        self.model = model_type(pretrained=pretrained)\n",
        "        \n",
        "        if pretrained:\n",
        "            for parma in self.model.parameters():\n",
        "                parma.requires_grad = False\n",
        "\n",
        "        num_ftrs = self.model.classifier.in_features\n",
        "        self.model.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "                 \n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class AnsambleModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(AnsambleModel, self).__init__()\n",
        "\n",
        "        self.models = nn.ModuleList([\n",
        "            #MyNet(num_classes, in_dim=32),\n",
        "            MyResNet(num_classes, model='resnet18', pretrained=True),\n",
        "            #MyResNet(num_classes, model='resnet152', pretrained=True),\n",
        "            #MyVGG(num_classes, model='vgg16', pretrained=True),\n",
        "            #MyDense(num_classes, model='densenet121', pretrained=True),\n",
        "            #MyDense(num_classes, model='densenet201', pretrained=True)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = [m(x) for m in self.models]\n",
        "        x = torch.stack(x, axis=0)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xclKdg5Rbdey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AnsableCEL(nn.Module):\n",
        "    def __init__(self, margin=1.0, p=2, part=1.0):\n",
        "        super(AnsableCEL, self).__init__()\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, xs, ys):\n",
        "        losses = []\n",
        "        for x in xs:\n",
        "            losses += [self.criterion(x, ys)]\n",
        "        losses = torch.stack(losses)\n",
        "        loss = losses.sum()\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wJTRcl1cmhsP",
        "colab": {}
      },
      "source": [
        "def train(model, criterion, optimizer, scheduler, epochs):\n",
        "    wandb.init(project=\"hse08_ip_hw_3\")\n",
        "\n",
        "    best_model = [copy.deepcopy(m) for m in model.models]\n",
        "    best_accuracy = [0 for _ in model.models]\n",
        "    for _ in trange(epochs):\n",
        "        for xs, ys in train_data_loader:\n",
        "            xs = xs.to(device)\n",
        "            ys = ys.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(xs)\n",
        "            loss = criterion(outputs, ys)\n",
        "\n",
        "            wandb.log({'Train loss': loss.item()})\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        losses = []\n",
        "        accuracy = [(0, 0) for _ in model.models]\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for xs, ys in val_data_loader:\n",
        "                xs = xs.to(device)\n",
        "                ys = ys.to(device)\n",
        "\n",
        "                outputs = model(xs)\n",
        "                loss = criterion(outputs, ys)\n",
        "                for i, out in enumerate(outputs):\n",
        "                    true_detections = (ys == out.argmax(axis=1)).sum().item()\n",
        "                    accuracy[i] = (accuracy[i][0] + true_detections,\n",
        "                                   accuracy[i][1] + ys.shape[0])\n",
        "                \n",
        "                losses += [loss.item()]\n",
        "            \n",
        "        model.train()\n",
        "\n",
        "        loss = np.array(losses).mean()\n",
        "        wandb.log({'Val loss': loss})\n",
        "        for i, (acs, ss) in enumerate(accuracy):\n",
        "            ac = acs / ss\n",
        "            wandb.log({f'Accuracy {i + 1}': ac})\n",
        "            \n",
        "            if best_accuracy[i] < ac:\n",
        "                best_accuracy[i] = ac\n",
        "                best_model[i] = copy.deepcopy(model.models[i])\n",
        "        \n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "    for i, m in enumerate(best_model):\n",
        "        model.models[i] = m\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oyOG67L1O8jP",
        "colab": {}
      },
      "source": [
        "def get_scores_for_one(model, xs):\n",
        "    scores = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(xs), BATCH_SIZE):\n",
        "            j = min(i + BATCH_SIZE, len(xs))\n",
        "            batch_xs = xs[i:j]\n",
        "\n",
        "            batch_xs = [torch.FloatTensor(np.array(x)) for x in batch_xs]\n",
        "            batch_xs = collate_xs(batch_xs)\n",
        "            batch_xs = batch_xs.to(device)\n",
        "\n",
        "            batch_scores = model(batch_xs).reshape(j - i, -1)\n",
        "            batch_scores = F.softmax(batch_scores, dim=-1)\n",
        "            batch_scores = batch_scores.cpu().numpy()\n",
        "            \n",
        "            scores += [batch_scores]\n",
        "\n",
        "    scores = np.concatenate(scores, axis=0)\n",
        "\n",
        "    return scores\n",
        "\n",
        "def get_scores(model, xs):\n",
        "    scores = [get_scores_for_one(m, xs) for m in model.models]\n",
        "    scores = np.stack(scores, axis=1)\n",
        "    return scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrtiPRRgLowV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predictions(scores, f):\n",
        "    if f == 'mean':\n",
        "        ys = scores.mean(axis=1).argmax(axis=1)\n",
        "    elif f == 'vote':\n",
        "        ys = scores.argmax(axis=2)\n",
        "        ys = [np.bincount(y).argmax() for y in ys]\n",
        "        ys = np.stack(ys, axis=0)\n",
        "\n",
        "    return ys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nljJt5Yp5eo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_nn_accuracy(scores, ys, f):\n",
        "    ys_predicted = get_predictions(scores, f)\n",
        "    return (ys_predicted == ys).sum() / len(ys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-2gswDpcPta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_model = AnsambleModel(num_classes=67)\n",
        "#nn_model.load_state_dict(torch.load('model.pth'))\n",
        "nn_model.to(device)\n",
        "\n",
        "criterion = AnsableCEL()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gkfQcIe8mhsV",
        "colab": {}
      },
      "source": [
        "LR = 0.001\n",
        "EPOCHS = 4\n",
        "\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, nn_model.parameters()), \n",
        "                       LR)\n",
        "\n",
        "nn_model.train()\n",
        "nn_model = train(nn_model, criterion, optimizer, None, EPOCHS)\n",
        "\n",
        "torch.save(nn_model.state_dict(), 'model.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2yQVI_drf21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR = 0.0001\n",
        "EPOCHS = 5\n",
        "\n",
        "for parma in nn_model.parameters():\n",
        "    parma.requires_grad = True\n",
        "\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, nn_model.parameters()), \n",
        "                       LR)\n",
        "\n",
        "nn_model.train()\n",
        "nn_model = train(nn_model, criterion, optimizer, None, EPOCHS)\n",
        "\n",
        "torch.save(nn_model.state_dict(), 'model.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e894DlqSDTDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_model.eval()\n",
        "\n",
        "train_scores = get_scores(nn_model, x_train)\n",
        "val_scores = get_scores(nn_model, x_val)\n",
        "\n",
        "train_nn_accuracy = get_nn_accuracy(train_scores, y_train, f='vote')\n",
        "val_nn_accuracy = get_nn_accuracy(val_scores, y_val, f='vote')\n",
        "\n",
        "print(f'Train NN accuracy vote {train_nn_accuracy}')\n",
        "print(f'Val NN accuracy vote {val_nn_accuracy}')\n",
        "\n",
        "train_nn_accuracy = get_nn_accuracy(train_scores, y_train, f='mean')\n",
        "val_nn_accuracy = get_nn_accuracy(val_scores, y_val, f='mean')\n",
        "\n",
        "print(f'Train NN accuracy mean {train_nn_accuracy}')\n",
        "print(f'Val NN accuracy mean {val_nn_accuracy}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLYVTQfgmgpq",
        "colab": {}
      },
      "source": [
        "images = []\n",
        "with zipfile.ZipFile(PATH_DATA, 'r') as zip_file:\n",
        "    image_names = [f[10:] for f in zip_file.namelist() if 'test' in f]\n",
        "\n",
        "    for name in image_names:\n",
        "        with zip_file.open(os.path.join('test', 'test', name)) as img_file:\n",
        "            image = Image.open(img_file).convert('RGB')\n",
        "        images += [(name, image)]\n",
        "\n",
        "predictions = {'filename': [], 'class_number': []}\n",
        "with torch.no_grad():\n",
        "    for i in trange(0, len(images), BATCH_SIZE):\n",
        "        j = min(i + BATCH_SIZE, len(images))\n",
        "        batch = images[i:j]\n",
        "        _, xs = zip(*batch)\n",
        "        scores = get_scores(nn_model, xs)\n",
        "        ys = get_predictions(scores, f='mean')\n",
        "\n",
        "        for (name, _), y in zip(images[i:j], ys):\n",
        "            predictions['filename'] += [name]\n",
        "            predictions['class_number'] += [y]\n",
        "\n",
        "predictions = pd.DataFrame(predictions)\n",
        "predictions.to_csv('test_neural.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}